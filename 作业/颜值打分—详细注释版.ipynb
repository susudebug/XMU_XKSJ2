{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 实践任务：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ed6691c01b5141b1940645c613c15045fb20ae2643164862b9bad94787e2cbf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 环境介绍\n",
    "\n",
    "python==3.7 \n",
    "\n",
    "paddle==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据集介绍\n",
    "训练数据集为华南理工大学实验室公布的数据集\n",
    "\n",
    "数据中包含500张女生图片，分别由70人进行打分，最终取平均值即为该图片的打分情况。\n",
    "\n",
    "我们在实践中将图片分值设定为1-5。\n",
    "\n",
    "500张图片中，450张用于训练，50张用于验证。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9d213946134f4fc4abba86a4f5c8de829cf6b62b9d074fceb6d22c2e1c8fb71e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**任务：分析、利用给定的数据集，训练一个人脸颜值打分模型，给出模型在验证集上的准确率，并利用模型给 work/1.jpg 图片打分**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 配置环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data18736  dataset\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddlex==2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.0.0)\n",
      "Requirement already satisfied: motmetrics in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (1.4.0)\n",
      "Requirement already satisfied: lap in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (0.4.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (1.6.3)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (0.4.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (4.36.1)\n",
      "Requirement already satisfied: chardet in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (3.0.4)\n",
      "Requirement already satisfied: pycocotools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (2.0.6)\n",
      "Requirement already satisfied: scikit-learn==0.23.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (0.23.2)\n",
      "Requirement already satisfied: visualdl>=2.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (2.2.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (5.1.2)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (4.1.1.26)\n",
      "Requirement already satisfied: paddleslim==2.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (2.1.1)\n",
      "Requirement already satisfied: shapely>=1.7.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (23.2.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (2.2.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1->paddlex==2.0.0) (8.2.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.0.0) (1.20.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.0.0) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex==2.0.0) (2.1.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (3.20.1)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.1.1)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (0.7.1.1)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (2.22.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (0.8.53)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.21.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (4.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.1.5)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.1.1->paddlex==2.0.0) (1.16.0)\n",
      "Requirement already satisfied: xmltodict>=0.12.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from motmetrics->paddlex==2.0.0) (0.13.0)\n",
      "Requirement already satisfied: pycodestyle<2.9.0,>=2.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (2.8.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (0.6.1)\n",
      "Requirement already satisfied: importlib-metadata<4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (4.2.0)\n",
      "Requirement already satisfied: pyflakes<2.5.0,>=2.4.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (2.4.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (3.0.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (0.16.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (7.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.1.1->paddlex==2.0.0) (2019.3)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.1.1->paddlex==2.0.0) (2.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (0.10.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.1.1->paddlex==2.0.0) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.1.1->paddlex==2.0.0) (0.18.0)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (16.7.9)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (0.10.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.3.4)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.3.0)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.1.1->paddlex==2.0.0) (1.4.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.1.1->paddlex==2.0.0) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (4.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata<4.3->flake8>=3.7.9->visualdl>=2.1.1->paddlex==2.0.0) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.1.1->paddlex==2.0.0) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->paddleslim==2.1.1->paddlex==2.0.0) (56.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data\n",
    "!pip install paddlex==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting beautifulsoup4\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/57/f4/a69c20ee4f660081a7dedb1ac57f29be9378e04edfcb90c526b923d4bebc/beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/49/37/673d6490efc51ec46d198c75903d99de59baffdd47aea3d071b80a9e4e89/soupsieve-2.4.1-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.2 soupsieve-2.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "!mkdir /home/aistudio/external-libraries\n",
    "!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/distributed/parallel.py:136: UserWarning: Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\n",
      "  \"Currently not a parallel execution environment, `paddle.distributed.init_parallel_env` will not do anything.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06-02 15:50:06 MainThread @utils.py:79] WRN paddlepaddle version: 2.2.2. The dynamic graph version of PARL is under development, not fully tested and supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: FutureWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  context = pyarrow.default_serialization_context()\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/common/analyze_helper.py:22: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://matplotlib_inline.backend_inline' by the following code:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures, cell_id\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1951/3522363527.py\", line 10, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:130: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    }
   ],
   "source": [
    "#导入需要的包\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import paddle\n",
    "import matplotlib.pyplot as plt\n",
    "from paddle.io import Dataset\n",
    "import shutil\n",
    "\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph import Linear\n",
    "import paddlex as pdx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "参数配置\n",
    "'''\n",
    "train_parameters = {\n",
    "    \"input_size\": [3,224,224],                           #输入图片的shape\n",
    "    \"class_dim\": -1,                                     #分类数\n",
    "    \"src_path\":\"data/data18736/face_data_5.zip\",       #原始数据集路径\n",
    "    \"target_path\":\"/home/aistudio/data/dataset\",        #要解压的路径 \n",
    "    \"train_list_path\": \"./train.txt\",              #train_data.txt路径\n",
    "    \"eval_list_path\": \"./eval.txt\",                  #eval_data.txt路径\n",
    "    \"label_list_path\": \"./label.txt\",                  #eval_data.txt路径\n",
    "    \"test_list_path\": \"./test.txt\",                  #test_data.txt路径\n",
    "    \"label_dict\":{},                                    #标签字典\n",
    "    \"readme_path\": \"/home/aistudio/data/readme.json\",   #readme.json路径\n",
    "    \"num_epochs\": 40,                                    #训练轮数\n",
    "    \"train_batch_size\": 16,                             #批次的大小\n",
    "    \"learning_strategy\": {                              #优化函数相关的配置\n",
    "        \"lr\": 0.01                                     #超参数学习率\n",
    "    } ,\n",
    "    \"checkpoints\": \"/home/aistudio/work/checkpoints\",          #保存的路径\n",
    "    \"skip_steps\": 10,                                     #训练时输出日志的间隔\n",
    "    \"save_steps\": 100,                                        #训练时保存模型参数的间隔\n",
    "    \"class_path\":  \"/home/aistudio/data_new\",   #按分数分类的新的图片地址\n",
    "    \"augment_path\":\"/home/aistudio/data/dataset/face_data_5/face_image_train\"   #数据增强图片目录\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 定义解压函数unzip_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unzip_data(src_path,target_path):\n",
    "\n",
    "    '''\n",
    "    解压原始数据集，将src_path路径下的zip包解压至data目录下\n",
    "    '''\n",
    "    if(not os.path.isdir(target_path)):    \n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()\n",
    "    else:\n",
    "        print(\"文件已解压\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 定义划分基础数据列表函数get_data_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#划分基础数据列表\n",
    "from shutil import copyfileobj\n",
    "def get_data_list1(target_path,train_list_path,val_list_path,label_list_path):\n",
    "    '''\n",
    "    生成数据列表\n",
    "    '''\n",
    "    #存储要写进eval.txt和train.txt中的内容\n",
    "    trainer_list=[]\n",
    "    eval_list=[]\n",
    "    label_list=[]\n",
    "\n",
    "    #获取所有类别保存的文件夹名称\n",
    "    data_list_path=target_path\n",
    "    class_dirs = os.listdir(data_list_path)\n",
    "    \n",
    "    #print(target_path)\n",
    "    if '__MACOSX' in class_dirs:\n",
    "        class_dirs.remove('__MACOSX')\n",
    "\n",
    "\n",
    "    #读取每个类别\n",
    "    for class_dir in class_dirs:\n",
    "        if class_dir != \".DS_Store\":\n",
    "            eval_sum = 0\n",
    "            trainer_sum = 0\n",
    "\n",
    "            #统计每个类别有多少张图片\n",
    "            class_sum = 0\n",
    "\n",
    "            #获取类别路径 \n",
    "            path = os.path.join(data_list_path,class_dir)\n",
    "            #print(path)\n",
    "            # 获取所有图片\n",
    "            img_paths = os.listdir(path)\n",
    "            for img_path in img_paths:                                  # 遍历文件夹下的每个图片\n",
    "                if (img_path =='.DS_Store')|(img_path=='face_image_test'):\n",
    "                    continue\n",
    "                name_path = os.path.join(path,img_path)                       # 每张图片的路径\n",
    "                print(name_path)\n",
    "                for x in os.listdir(name_path):\n",
    "\n",
    "                    y=os.path.join(name_path,x)\n",
    "                    print(y)\n",
    "                    if class_sum % 10 == 0:                                 # 每10张图片取一个做验证数据\n",
    "                        eval_sum += 1                                       # eval_sum为测试数据的数目\n",
    "                        new_eval='/home/aistudio/eval/'+x \n",
    "                        print(new_eval)\n",
    "                        shutil.copy(y,new_eval)  \n",
    "                        eval_list.append(new_eval + \"\\t%d\" % int(x[0],10) + \"\\n\")\n",
    "                    else:\n",
    "                        trainer_sum += 1\n",
    "                        new_train='/home/aistudio/train/'+x \n",
    "                        shutil.copy(y,new_train)   \n",
    "                        trainer_list.append(new_train + \"\\t%d\" % int(x[0],10) + \"\\n\")#trainer_sum测试数据的数目\n",
    "                    class_sum += 1                                          #每类图片的数目\n",
    "            \n",
    "    for i in range(1,6):\n",
    "        label_list.append(str(i)+\"\\n\")\n",
    "\n",
    "    #print(train_parameters)\n",
    "    #乱序  \n",
    "    random.shuffle(eval_list)\n",
    "    with open(eval_list_path, 'a') as f:\n",
    "        for eval_image in eval_list:\n",
    "            f.write(eval_image) \n",
    "    #乱序        \n",
    "    random.shuffle(trainer_list) \n",
    "    with open(train_list_path, 'a') as f2:\n",
    "        for train_image in trainer_list:\n",
    "            f2.write(train_image)\n",
    "\n",
    "    with open(label_list_path, 'a') as f2:\n",
    "        for label in label_list:\n",
    "            f2.write(label)  \n",
    "\n",
    "\n",
    "    print ('生成数据列表完成！')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已解压\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "参数初始化\n",
    "'''\n",
    "src_path=train_parameters['src_path']\n",
    "target_path=train_parameters['target_path']\n",
    "train_list_path=train_parameters['train_list_path']\n",
    "eval_list_path=train_parameters['eval_list_path']\n",
    "label_list_path=train_parameters['label_list_path']\n",
    "batch_size=train_parameters['train_batch_size']\n",
    "class_path=train_parameters['class_path']\n",
    "\n",
    "'''\n",
    "解压原始数据到指定路径\n",
    "'''\n",
    "train_parameters[\"target_path\"]=\"/home/aistudio/data/dataset\"\n",
    "target_path=train_parameters[\"target_path\"]\n",
    "unzip_data(src_path,target_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 获取基础数据列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成数据列表 \n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-68.jpg\n",
      "/home/aistudio/eval/3-68.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-231.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-14.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-198.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-66.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-388.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-20.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-378.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-157.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-455.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-423.jpg\n",
      "/home/aistudio/eval/2-423.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-175.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-308.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-193.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-415.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/1-112.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-61.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-229.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-72.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-180.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-324.jpg\n",
      "/home/aistudio/eval/2-324.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-93.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-278.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-301.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-62.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-52.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-238.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-453.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-406.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-422.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-289.jpg\n",
      "/home/aistudio/eval/2-289.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-248.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-12.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-8.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-251.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-487.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-321.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-472.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-441.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-3.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-130.jpg\n",
      "/home/aistudio/eval/2-130.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-172.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-331.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-412.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-371.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-199.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-268.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-69.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-410.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-417.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-266.jpg\n",
      "/home/aistudio/eval/2-266.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-475.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-162.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-405.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-296.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-104.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-179.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-380.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-437.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-300.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-83.jpg\n",
      "/home/aistudio/eval/3-83.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-452.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-95.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-131.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-303.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-500.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-420.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-253.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-283.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-352.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-230.jpg\n",
      "/home/aistudio/eval/3-230.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-26.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-154.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-209.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-13.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-317.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-212.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-80.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-419.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-156.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-284.jpg\n",
      "/home/aistudio/eval/2-284.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-225.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-431.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-310.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-113.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-462.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-201.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-351.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-53.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-215.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-392.jpg\n",
      "/home/aistudio/eval/3-392.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-224.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-2.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-107.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-260.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-413.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-373.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-391.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-123.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-320.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-30.jpg\n",
      "/home/aistudio/eval/2-30.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-183.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-135.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-468.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-393.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-482.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-471.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/1-159.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-439.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-214.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-143.jpg\n",
      "/home/aistudio/eval/3-143.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-165.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-329.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-59.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-176.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-341.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-19.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-291.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-399.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-150.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-369.jpg\n",
      "/home/aistudio/eval/3-369.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-217.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-385.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-467.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-448.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-275.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-210.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-313.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-208.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-414.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-474.jpg\n",
      "/home/aistudio/eval/3-474.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-386.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-358.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-476.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-133.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-216.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-11.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-353.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-306.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-169.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-488.jpg\n",
      "/home/aistudio/eval/3-488.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-40.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-237.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-146.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-383.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-264.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-128.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-139.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-64.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-223.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-119.jpg\n",
      "/home/aistudio/eval/2-119.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-344.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-117.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-402.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-196.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-81.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-442.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-356.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-361.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-496.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-255.jpg\n",
      "/home/aistudio/eval/2-255.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-77.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-340.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-377.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-497.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-24.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-484.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-347.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-428.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-244.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-464.jpg\n",
      "/home/aistudio/eval/2-464.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-295.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-261.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-470.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-433.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-124.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-424.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-401.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-262.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-355.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-65.jpg\n",
      "/home/aistudio/eval/2-65.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-270.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-170.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-122.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-374.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-76.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-339.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-163.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-207.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-56.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-221.jpg\n",
      "/home/aistudio/eval/2-221.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-319.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-195.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-350.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-178.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-346.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-446.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-357.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-188.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-181.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-493.jpg\n",
      "/home/aistudio/eval/3-493.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-84.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-305.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-367.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-366.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-429.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-325.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-75.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-171.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-31.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-101.jpg\n",
      "/home/aistudio/eval/5-101.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-240.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-403.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-242.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-129.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-202.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-286.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-39.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-375.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-236.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-460.jpg\n",
      "/home/aistudio/eval/3-460.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-233.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-430.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-365.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-63.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-332.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-271.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-85.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-336.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-92.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-73.jpg\n",
      "/home/aistudio/eval/2-73.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-466.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-49.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-218.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-111.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-155.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-51.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-120.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-473.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-245.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-121.jpg\n",
      "/home/aistudio/eval/2-121.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-348.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-89.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-235.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-79.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-370.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-389.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-443.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-246.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-222.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-132.jpg\n",
      "/home/aistudio/eval/3-132.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-70.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-293.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-290.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-486.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-250.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-451.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-302.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-137.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-483.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-249.jpg\n",
      "/home/aistudio/eval/2-249.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-491.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-140.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-10.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-274.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-86.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-1.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-173.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-144.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-287.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-265.jpg\n",
      "/home/aistudio/eval/3-265.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-312.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-17.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-311.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-259.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-99.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-330.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-477.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-333.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-280.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-58.jpg\n",
      "/home/aistudio/eval/4-58.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-272.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-22.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-115.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-134.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-327.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-126.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-151.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-118.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-267.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-396.jpg\n",
      "/home/aistudio/eval/2-396.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-458.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-359.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-277.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-211.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-376.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-205.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-440.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-354.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-363.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-381.jpg\n",
      "/home/aistudio/eval/5-381.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-102.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-461.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-153.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-294.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-204.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-298.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-337.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-478.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-149.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-187.jpg\n",
      "/home/aistudio/eval/2-187.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-447.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-334.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-127.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-108.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-91.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-400.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-450.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-166.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-273.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-480.jpg\n",
      "/home/aistudio/eval/2-480.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-297.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-48.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-397.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-18.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-60.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-189.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-479.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-228.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-335.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-160.jpg\n",
      "/home/aistudio/eval/2-160.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-445.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-194.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-285.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-421.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-114.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-408.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-307.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-168.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-5.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-292.jpg\n",
      "/home/aistudio/eval/2-292.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-35.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-409.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-418.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-98.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-457.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-43.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-364.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-368.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-416.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-37.jpg\n",
      "/home/aistudio/eval/4-37.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-258.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-9.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-309.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-342.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-362.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-167.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-158.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-338.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-54.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-404.jpg\n",
      "/home/aistudio/eval/3-404.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-444.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-232.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-192.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-227.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-191.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-25.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-23.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-116.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-435.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-186.jpg\n",
      "/home/aistudio/eval/5-186.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-32.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-427.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-41.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-315.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-47.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-256.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-382.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-174.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-74.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-434.jpg\n",
      "/home/aistudio/eval/2-434.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-109.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-71.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-213.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-177.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-239.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-379.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-206.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-78.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-42.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-454.jpg\n",
      "/home/aistudio/eval/3-454.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-494.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-459.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-390.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-226.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-82.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-269.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-318.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-55.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-495.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-395.jpg\n",
      "/home/aistudio/eval/3-395.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-16.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-343.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-426.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-184.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-142.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-254.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-148.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-141.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-499.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-145.jpg\n",
      "/home/aistudio/eval/3-145.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-498.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-197.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-100.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-147.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-219.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-425.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-288.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-110.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-241.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-372.jpg\n",
      "/home/aistudio/eval/2-372.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-463.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-276.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-136.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-243.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-36.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-106.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-44.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-29.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-50.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-182.jpg\n",
      "/home/aistudio/eval/3-182.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-432.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-96.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-234.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-279.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/5-105.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-21.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-257.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-67.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-387.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-125.jpg\n",
      "/home/aistudio/eval/3-125.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-7.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-263.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-456.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-314.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-322.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/4-326.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-138.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/2-152.jpg\n",
      "/home/aistudio/data/dataset/face_data_5/face_image_train/3-34.jpg\n",
      "生成数据列表完成！\n"
     ]
    }
   ],
   "source": [
    "#每次生成数据列表前，首先清空train.txt和eval.txt\n",
    "\n",
    "with open(train_list_path, 'w') as f: \n",
    "    f.seek(0)\n",
    "    f.truncate() \n",
    "with open(eval_list_path, 'w') as f: \n",
    "    f.seek(0)\n",
    "    f.truncate() \n",
    "with open(label_list_path, 'w') as f: \n",
    "    f.seek(0)\n",
    "    f.truncate() \n",
    "\n",
    "\n",
    "if not os.path.exists('/home/aistudio/train'): \n",
    "    os.mkdir(r'/home/aistudio/train')\n",
    "    os.mkdir(r'/home/aistudio/eval')\n",
    "    train_parameters[\"target_path\"]=\"/home/aistudio/data/dataset\"\n",
    "    target_path=train_parameters[\"target_path\"]\n",
    "    print(\"生成数据列表 \")\n",
    "    #生成数据列表  \n",
    "    get_data_list1(target_path,train_list_path,eval_list_path,label_list_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def proc_img(src):\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        if '__MACOSX' in root:continue\n",
    "        for file in files:            \n",
    "            src=os.path.join(root,file)\n",
    "            img=Image.open(src)\n",
    "            if img.mode != 'RGB': \n",
    "                    img = img.convert('RGB') \n",
    "                    img.save(src)            \n",
    "\n",
    "if __name__=='__main__':\n",
    "    proc_img(r\"/home/aistudio/data_new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 做数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting Augmentor\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f3/86/5a91176650eb229ea2cd95551c34c36fba6cd95da3bdc4a5c73fbb1536ca/Augmentor-0.2.12-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: Pillow>=5.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Augmentor) (8.2.0)\n",
      "Requirement already satisfied: tqdm>=4.9.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Augmentor) (4.36.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Augmentor) (1.20.3)\n",
      "Installing collected packages: Augmentor\n",
      "Successfully installed Augmentor-0.2.12\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.1.2\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_ /home/aistudio/train\n",
      "数据增强： /home/aistudio/train\n",
      "image： /home/aistudio/train\n",
      "Initialised with 405 image(s) found.\n",
      "Output directory set to /home/aistudio/train/output.Initialised with 405 image(s) found.\n",
      "Output directory set to /home/aistudio/train/output.Initialised with 405 image(s) found.\n",
      "Output directory set to /home/aistudio/train/output."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing Pipeline: 0 Samples [00:00, ? Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=224x224 at 0x7F69ACE7C650>: 100%|██████████| 405/405 [00:01<00:00, 316.02 Samples/s]                 \n",
      "Executing Pipeline: 0 Samples [00:00, ? Samples/s]\n",
      "Processing <PIL.Image.Image image mode=RGB size=224x224 at 0x7F69AC499750>: 100%|██████████| 405/405 [00:00<00:00, 440.52 Samples/s]                 \n",
      "Executing Pipeline: 0 Samples [00:00, ? Samples/s]\n",
      "Processing <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=224x224 at 0x7F69AC643A50>: 100%|██████████| 405/405 [00:01<00:00, 320.25 Samples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成数据增强\r"
     ]
    }
   ],
   "source": [
    "import Augmentor,glob,os,shutil\n",
    "augment_path=train_parameters['augment_path']\n",
    "# 设置输出目录，控制不重复增强数据\n",
    "\n",
    "\n",
    "path_ =\"/home/aistudio/train\"\n",
    "\n",
    "print(\"path_\",path_)\n",
    "print('数据增强：',path_)\n",
    "print('image：',path_)\n",
    "\n",
    "#创建 Augmentor.Pipeline 实例，并指定需要增强的图片所在目录，设置增强操作的参数，如旋转、缩放、扭曲等\n",
    "p = Augmentor.Pipeline(path_,output_directory='output')\n",
    "b = Augmentor.Pipeline(path_,output_directory='output')\n",
    "c = Augmentor.Pipeline(path_,output_directory='output')\n",
    "#ouput为中间目录，最后需要删除\n",
    "\n",
    "\n",
    "#p.rotate()方法来设置旋转增强的概率（probability）\n",
    "#最大左旋角度（max_left_rotation）\n",
    "#最大右旋角度（max_right_rotation）\n",
    "p.rotate(probability=0.6, max_left_rotation=2, max_right_rotation=2)\n",
    "\n",
    "#p.zoom()方法用于设置缩放增强的概率（probability）\n",
    "#最小缩放因子（min_factor）\n",
    "#最大缩放因子（max_factor）\n",
    "b.zoom(probability=0.6, min_factor=0.9, max_factor=1.1)\n",
    "\n",
    "#p.random_distortion()方法用于设置扭曲增强的概率（probability）\n",
    "#网格高度（grid_height）、网格宽度（grid_width）和扭曲强度（magnitude）\n",
    "c.random_distortion(probability=0.4, grid_height=2, grid_width=2, magnitude=1)\n",
    "\n",
    "# 根据已有图片数量计算需要增强的数量\n",
    "count = 200 - len(glob.glob(pathname=path_+'/*.jpg'))\n",
    "\n",
    "#调用 sample() 方法进行样本扩增。\n",
    "p.sample(count, multi_threaded=False)\n",
    "p.process()\n",
    "#调用 sample() 方法进行样本扩增。\n",
    "b.sample(count, multi_threaded=False)\n",
    "b.process()\n",
    "#调用 sample() 方法进行样本扩增。\n",
    "c.sample(count, multi_threaded=False)\n",
    "c.process()\n",
    "\n",
    "print('将生成的图片拷贝到正确的目录')\n",
    "for root, dirs, files in os.walk(\"/home/aistudio/train\", topdown=False):\n",
    "    for name in files:\n",
    "        path_ = os.path.join(root, name)\n",
    "        #print(path_)\n",
    "        name2=name\n",
    "        substring = \"train_original_\"\n",
    "        name2 = name.replace(substring, '')\n",
    "        #print(name2) \n",
    "\n",
    "        if path_.rsplit('/',3)[2] == 'output':\n",
    "            dest_dir = os.path.join(augment_path ,'train') \n",
    "            #print(dest_dir)\n",
    "            if not os.path.exists(dest_dir):os.makedirs(dest_dir) \n",
    "            dest_path_ = os.path.join(augment_path ,name2) \n",
    "            shutil.move(path_, dest_path_)\n",
    "            print(dest_path_)\n",
    "print('删除所有output目录')\n",
    "for root, dirs, files in os.walk(\"/home/aistudio/train\", topdown=False):\n",
    "    for name in dirs:\n",
    "        if name == 'output':\n",
    "            path_ = os.path.join(root, name)\n",
    "            shutil.rmtree(path_)\n",
    "print('完成数据增强')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 定义获取增强数据列表函数add_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#增强数据列表\n",
    "\n",
    "def add_data_list(train_list_path,augment_path):\n",
    "    '''\n",
    "    生成数据列表\n",
    "    '''\n",
    "    #存储要写进eval.txt和train.txt中的内容\n",
    "    add_list=[]\n",
    "\n",
    "    #获取所有类别保存的文件夹名称\n",
    "    add_list_path=augment_path\n",
    "    add_imgs = os.listdir(add_list_path)\n",
    "    \n",
    "    #print(target_path)\n",
    "    if 'train' in add_imgs:\n",
    "        add_imgs.remove('train')\n",
    "    #读取每个类别\n",
    "    for add_img in add_imgs:\n",
    "        if add_img != \".DS_Store\":\n",
    "            #获取类别路径 \n",
    "            add_path = os.path.join(add_list_path,add_img)\n",
    "            add_list.append(add_path + \"\\t%d\" % int(add_img[0],10) + \"\\n\")#trainer_sum测试数据的数目\n",
    "\n",
    "    #print(train_parameters)\n",
    "    #乱序  \n",
    "    random.shuffle(add_list)\n",
    "    with open(train_list_path, 'a') as f:\n",
    "        for add_image in add_list:\n",
    "            f.write(add_image) \n",
    "    print ('生成数据列表完成！')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 将增广后的数据加入train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成数据列表完成！\n"
     ]
    }
   ],
   "source": [
    "#将增广的数据加入train_list\n",
    "add_data_list(train_list_path,augment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据读取器定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddle.vision import transforms as T\n",
    "\n",
    "class Reader(Dataset):\n",
    "    def __init__(self, data_path, mode='train'):\n",
    "        \"\"\"\n",
    "        数据读取器\n",
    "        :param data_path: 数据集所在路径\n",
    "        :param mode: train or eval\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.img_paths = []\n",
    "        self.labels = []\n",
    "        if mode == 'train':\n",
    "            with open(os.path.join(self.data_path, \"train.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "                self.info = f.readlines()\n",
    "            for img_info in self.info:\n",
    "                img_path, label = img_info.strip().split('\\t')\n",
    "                self.img_paths.append(img_path)\n",
    "                self.labels.append(int(label))\n",
    "\n",
    "        else:\n",
    "            with open(os.path.join(self.data_path, \"eval.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "                self.info = f.readlines()\n",
    "            for img_info in self.info:\n",
    "                img_path, label = img_info.strip().split('\\t')\n",
    "                self.img_paths.append(img_path)\n",
    "                self.labels.append(int(label))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取一组数据\n",
    "        :param index: 文件索引号\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 第一步打开图像文件并获取label值\n",
    "        img_path = self.img_paths[index]\n",
    "        img = Image.open(img_path)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB') \n",
    "        img = img.resize((224, 224), Image.BILINEAR)\n",
    "        img = np.array(img).astype('float32')\n",
    "        img = img.transpose((2, 0, 1)) / 255\n",
    "        label = self.labels[index]\n",
    "        label = np.array([label], dtype=\"int64\")\n",
    "        return img, label\n",
    "\n",
    "    def print_sample(self, index: int = 0):\n",
    "        print(\"文件名\", self.img_paths[index], \"\\t标签值\", self.labels[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2070\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Reader('/home/aistudio/',mode='train')\n",
    "print(train_dataset.__len__())\n",
    "eval_dataset = Reader('/home/aistudio/',mode='eval')\n",
    "print(eval_dataset.__len__())\n",
    "#训练数据加载\n",
    "train_loader = paddle.io.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "#测试数据加载\n",
    "eval_loader = paddle.io.DataLoader(eval_dataset, batch_size = 8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 查看数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2070\n",
      "45\n",
      "(3, 224, 224)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_dataset.__len__())\n",
    "print(eval_dataset.__len__())\n",
    "print(eval_dataset.__getitem__(10)[0].shape)\n",
    "print(eval_dataset.__getitem__(10)[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 使用resnet101_vd_ssld训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlex import transforms as T\n",
    "train_transforms = T.Compose(\n",
    "    [T.RandomCrop(crop_size=224), T.RandomHorizontalFlip(), T.Normalize()])\n",
    "\n",
    "eval_transforms = T.Compose([\n",
    "    T.ResizeByShort(short_size=256), T.CenterCrop(crop_size=224), T.Normalize()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:11:44 [INFO]\tStarting to read file list from dataset...\n",
      "2023-06-02 16:11:44 [INFO]\t2070 samples in file /home/aistudio/train.txt\n",
      "2023-06-02 16:11:44 [INFO]\tStarting to read file list from dataset...\n",
      "2023-06-02 16:11:44 [INFO]\t45 samples in file /home/aistudio/eval.txt\n",
      "5\n",
      "2023-06-02 16:11:44 [INFO]\tLoading pretrained model from output/resNet101_vd_ssld/pretrain/ResNet101_vd_ssld_pretrained.pdparams\n",
      "2023-06-02 16:11:45 [WARNING]\t[SKIP] Shape of pretrained params out.weight doesn't match.(Pretrained: [2048, 1000], Actual: [2048, 6])\n",
      "2023-06-02 16:11:45 [WARNING]\t[SKIP] Shape of pretrained params out.bias doesn't match.(Pretrained: [1000], Actual: [6])\n",
      "2023-06-02 16:11:45 [INFO]\tThere are 530/532 variables loaded into ResNet101_vd_ssld.\n",
      "2023-06-02 16:11:47 [INFO]\t[TRAIN] Epoch=1/40, Step=10/129, loss=1.060453, acc1=0.500000, acc5=1.000000, lr=0.005000, time_each_step=0.15s, eta=0:12:58\n",
      "2023-06-02 16:11:48 [INFO]\t[TRAIN] Epoch=1/40, Step=20/129, loss=1.221204, acc1=0.562500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:7\n",
      "2023-06-02 16:11:49 [INFO]\t[TRAIN] Epoch=1/40, Step=30/129, loss=1.148370, acc1=0.500000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:6\n",
      "2023-06-02 16:11:50 [INFO]\t[TRAIN] Epoch=1/40, Step=40/129, loss=1.096174, acc1=0.375000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:6\n",
      "2023-06-02 16:11:52 [INFO]\t[TRAIN] Epoch=1/40, Step=50/129, loss=0.660708, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:16\n",
      "2023-06-02 16:11:53 [INFO]\t[TRAIN] Epoch=1/40, Step=60/129, loss=1.274093, acc1=0.500000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:12\n",
      "2023-06-02 16:11:54 [INFO]\t[TRAIN] Epoch=1/40, Step=70/129, loss=0.954770, acc1=0.437500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:16\n",
      "2023-06-02 16:11:55 [INFO]\t[TRAIN] Epoch=1/40, Step=80/129, loss=1.129539, acc1=0.437500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:2\n",
      "2023-06-02 16:11:56 [INFO]\t[TRAIN] Epoch=1/40, Step=90/129, loss=0.869023, acc1=0.562500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:41\n",
      "2023-06-02 16:11:57 [INFO]\t[TRAIN] Epoch=1/40, Step=100/129, loss=0.886978, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:56\n",
      "2023-06-02 16:11:58 [INFO]\t[TRAIN] Epoch=1/40, Step=110/129, loss=1.047403, acc1=0.437500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:55\n",
      "2023-06-02 16:11:59 [INFO]\t[TRAIN] Epoch=1/40, Step=120/129, loss=0.891746, acc1=0.500000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:52\n",
      "2023-06-02 16:12:00 [INFO]\t[TRAIN] Epoch 1 finished, loss=0.97985923, acc1=0.54118216, acc5=0.99660856 .\n",
      "2023-06-02 16:12:00 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:12:01 [INFO]\t[EVAL] Finished, Epoch=1, acc1=0.647436, acc5=1.000000 .\n",
      "2023-06-02 16:12:03 [INFO]\tModel saved in output/resNet101_vd_ssld/best_model.\n",
      "2023-06-02 16:12:03 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_1, acc1=0.6474359035491943\n",
      "2023-06-02 16:12:06 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_1.\n",
      "2023-06-02 16:12:06 [INFO]\t[TRAIN] Epoch=2/40, Step=1/129, loss=0.539976, acc1=0.937500, acc5=1.000000, lr=0.005000, time_each_step=0.14s, eta=0:14:11\n",
      "2023-06-02 16:12:07 [INFO]\t[TRAIN] Epoch=2/40, Step=11/129, loss=0.621063, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:10:44\n",
      "2023-06-02 16:12:08 [INFO]\t[TRAIN] Epoch=2/40, Step=21/129, loss=0.774977, acc1=0.625000, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:10:30\n",
      "2023-06-02 16:12:09 [INFO]\t[TRAIN] Epoch=2/40, Step=31/129, loss=0.494792, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:11:6\n",
      "2023-06-02 16:12:10 [INFO]\t[TRAIN] Epoch=2/40, Step=41/129, loss=0.793941, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:56\n",
      "2023-06-02 16:12:12 [INFO]\t[TRAIN] Epoch=2/40, Step=51/129, loss=1.226858, acc1=0.562500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:11:1\n",
      "2023-06-02 16:12:13 [INFO]\t[TRAIN] Epoch=2/40, Step=61/129, loss=0.910208, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:57\n",
      "2023-06-02 16:12:14 [INFO]\t[TRAIN] Epoch=2/40, Step=71/129, loss=1.047575, acc1=0.562500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:56\n",
      "2023-06-02 16:12:15 [INFO]\t[TRAIN] Epoch=2/40, Step=81/129, loss=1.214418, acc1=0.375000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:11:4\n",
      "2023-06-02 16:12:16 [INFO]\t[TRAIN] Epoch=2/40, Step=91/129, loss=1.154940, acc1=0.625000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:56\n",
      "2023-06-02 16:12:17 [INFO]\t[TRAIN] Epoch=2/40, Step=101/129, loss=0.861533, acc1=0.625000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:53\n",
      "2023-06-02 16:12:18 [INFO]\t[TRAIN] Epoch=2/40, Step=111/129, loss=0.948217, acc1=0.625000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:53\n",
      "2023-06-02 16:12:19 [INFO]\t[TRAIN] Epoch=2/40, Step=121/129, loss=0.699888, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:56\n",
      "2023-06-02 16:12:20 [INFO]\t[TRAIN] Epoch 2 finished, loss=0.8371782, acc1=0.627907, acc5=1.0 .\n",
      "2023-06-02 16:12:20 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:12:21 [INFO]\t[EVAL] Finished, Epoch=2, acc1=0.549679, acc5=1.000000 .\n",
      "2023-06-02 16:12:21 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_1, acc1=0.6474359035491943\n",
      "2023-06-02 16:12:23 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_2.\n",
      "2023-06-02 16:12:24 [INFO]\t[TRAIN] Epoch=3/40, Step=2/129, loss=0.717061, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.14s, eta=0:12:17\n",
      "2023-06-02 16:12:25 [INFO]\t[TRAIN] Epoch=3/40, Step=12/129, loss=0.306503, acc1=0.937500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:51\n",
      "2023-06-02 16:12:26 [INFO]\t[TRAIN] Epoch=3/40, Step=22/129, loss=0.426222, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:42\n",
      "2023-06-02 16:12:27 [INFO]\t[TRAIN] Epoch=3/40, Step=32/129, loss=0.340707, acc1=0.875000, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:51\n",
      "2023-06-02 16:12:28 [INFO]\t[TRAIN] Epoch=3/40, Step=42/129, loss=0.487521, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:42\n",
      "2023-06-02 16:12:29 [INFO]\t[TRAIN] Epoch=3/40, Step=52/129, loss=0.625012, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:52\n",
      "2023-06-02 16:12:30 [INFO]\t[TRAIN] Epoch=3/40, Step=62/129, loss=0.425206, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:51\n",
      "2023-06-02 16:12:31 [INFO]\t[TRAIN] Epoch=3/40, Step=72/129, loss=0.383608, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:44\n",
      "2023-06-02 16:12:32 [INFO]\t[TRAIN] Epoch=3/40, Step=82/129, loss=0.665432, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:37\n",
      "2023-06-02 16:12:33 [INFO]\t[TRAIN] Epoch=3/40, Step=92/129, loss=0.687911, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:37\n",
      "2023-06-02 16:12:34 [INFO]\t[TRAIN] Epoch=3/40, Step=102/129, loss=0.701287, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:43\n",
      "2023-06-02 16:12:35 [INFO]\t[TRAIN] Epoch=3/40, Step=112/129, loss=0.952613, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:37\n",
      "2023-06-02 16:12:36 [INFO]\t[TRAIN] Epoch=3/40, Step=122/129, loss=0.833249, acc1=0.562500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:40\n",
      "2023-06-02 16:12:37 [INFO]\t[TRAIN] Epoch 3 finished, loss=0.6353846, acc1=0.7291667, acc5=1.0 .\n",
      "2023-06-02 16:12:37 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:12:38 [INFO]\t[EVAL] Finished, Epoch=3, acc1=0.709936, acc5=1.000000 .\n",
      "2023-06-02 16:12:40 [INFO]\tModel saved in output/resNet101_vd_ssld/best_model.\n",
      "2023-06-02 16:12:40 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_3, acc1=0.7099359035491943\n",
      "2023-06-02 16:12:43 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_3.\n",
      "2023-06-02 16:12:44 [INFO]\t[TRAIN] Epoch=4/40, Step=3/129, loss=0.781970, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.14s, eta=0:12:52\n",
      "2023-06-02 16:12:45 [INFO]\t[TRAIN] Epoch=4/40, Step=13/129, loss=0.484543, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:28\n",
      "2023-06-02 16:12:46 [INFO]\t[TRAIN] Epoch=4/40, Step=23/129, loss=0.659978, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:42\n",
      "2023-06-02 16:12:47 [INFO]\t[TRAIN] Epoch=4/40, Step=33/129, loss=0.688061, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:10:8\n",
      "2023-06-02 16:12:48 [INFO]\t[TRAIN] Epoch=4/40, Step=43/129, loss=0.794043, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:40\n",
      "2023-06-02 16:12:49 [INFO]\t[TRAIN] Epoch=4/40, Step=53/129, loss=0.636320, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:26\n",
      "2023-06-02 16:12:50 [INFO]\t[TRAIN] Epoch=4/40, Step=63/129, loss=1.019494, acc1=0.500000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:30\n",
      "2023-06-02 16:12:51 [INFO]\t[TRAIN] Epoch=4/40, Step=73/129, loss=0.549985, acc1=0.875000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:28\n",
      "2023-06-02 16:12:52 [INFO]\t[TRAIN] Epoch=4/40, Step=83/129, loss=0.297038, acc1=0.875000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:28\n",
      "2023-06-02 16:12:53 [INFO]\t[TRAIN] Epoch=4/40, Step=93/129, loss=0.603283, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:35\n",
      "2023-06-02 16:12:54 [INFO]\t[TRAIN] Epoch=4/40, Step=103/129, loss=0.406731, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:17\n",
      "2023-06-02 16:12:55 [INFO]\t[TRAIN] Epoch=4/40, Step=113/129, loss=0.407259, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:46\n",
      "2023-06-02 16:12:57 [INFO]\t[TRAIN] Epoch=4/40, Step=123/129, loss=0.615293, acc1=0.687500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:30\n",
      "2023-06-02 16:12:57 [INFO]\t[TRAIN] Epoch 4 finished, loss=0.6567103, acc1=0.7165698, acc5=1.0 .\n",
      "2023-06-02 16:12:58 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:12:58 [INFO]\t[EVAL] Finished, Epoch=4, acc1=0.605769, acc5=1.000000 .\n",
      "2023-06-02 16:12:58 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_3, acc1=0.7099359035491943\n",
      "2023-06-02 16:13:01 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_4.\n",
      "2023-06-02 16:13:02 [INFO]\t[TRAIN] Epoch=5/40, Step=4/129, loss=0.348889, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.14s, eta=0:11:19\n",
      "2023-06-02 16:13:03 [INFO]\t[TRAIN] Epoch=5/40, Step=14/129, loss=0.413077, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:19\n",
      "2023-06-02 16:13:04 [INFO]\t[TRAIN] Epoch=5/40, Step=24/129, loss=0.545609, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.1s, eta=0:8:18\n",
      "2023-06-02 16:13:05 [INFO]\t[TRAIN] Epoch=5/40, Step=34/129, loss=0.522506, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:46\n",
      "2023-06-02 16:13:06 [INFO]\t[TRAIN] Epoch=5/40, Step=44/129, loss=0.579162, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:50\n",
      "2023-06-02 16:13:07 [INFO]\t[TRAIN] Epoch=5/40, Step=54/129, loss=0.471843, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:42\n",
      "2023-06-02 16:13:08 [INFO]\t[TRAIN] Epoch=5/40, Step=64/129, loss=0.981982, acc1=0.625000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:36\n",
      "2023-06-02 16:13:09 [INFO]\t[TRAIN] Epoch=5/40, Step=74/129, loss=0.239580, acc1=1.000000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:34\n",
      "2023-06-02 16:13:10 [INFO]\t[TRAIN] Epoch=5/40, Step=84/129, loss=0.399911, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:39\n",
      "2023-06-02 16:13:12 [INFO]\t[TRAIN] Epoch=5/40, Step=94/129, loss=0.257195, acc1=0.875000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:36\n",
      "2023-06-02 16:13:13 [INFO]\t[TRAIN] Epoch=5/40, Step=104/129, loss=0.646548, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:30\n",
      "2023-06-02 16:13:14 [INFO]\t[TRAIN] Epoch=5/40, Step=114/129, loss=0.329937, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:28\n",
      "2023-06-02 16:13:15 [INFO]\t[TRAIN] Epoch=5/40, Step=124/129, loss=0.606602, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:8:32\n",
      "2023-06-02 16:13:15 [INFO]\t[TRAIN] Epoch 5 finished, loss=0.51128924, acc1=0.78100777, acc5=1.0 .\n",
      "2023-06-02 16:13:16 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:13:16 [INFO]\t[EVAL] Finished, Epoch=5, acc1=0.798077, acc5=1.000000 .\n",
      "2023-06-02 16:13:19 [INFO]\tModel saved in output/resNet101_vd_ssld/best_model.\n",
      "2023-06-02 16:13:19 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_5, acc1=0.7980769276618958\n",
      "2023-06-02 16:13:21 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_5.\n",
      "2023-06-02 16:13:22 [INFO]\t[TRAIN] Epoch=6/40, Step=5/129, loss=0.488942, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.14s, eta=0:12:41\n",
      "2023-06-02 16:13:23 [INFO]\t[TRAIN] Epoch=6/40, Step=15/129, loss=0.330497, acc1=0.937500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:4\n",
      "2023-06-02 16:13:24 [INFO]\t[TRAIN] Epoch=6/40, Step=25/129, loss=0.305327, acc1=0.875000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:54\n",
      "2023-06-02 16:13:25 [INFO]\t[TRAIN] Epoch=6/40, Step=35/129, loss=0.508243, acc1=0.875000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:0\n",
      "2023-06-02 16:13:26 [INFO]\t[TRAIN] Epoch=6/40, Step=45/129, loss=0.296600, acc1=0.812500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:55\n",
      "2023-06-02 16:13:27 [INFO]\t[TRAIN] Epoch=6/40, Step=55/129, loss=0.470401, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:52\n",
      "2023-06-02 16:13:29 [INFO]\t[TRAIN] Epoch=6/40, Step=65/129, loss=0.284776, acc1=0.937500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:59\n",
      "2023-06-02 16:13:30 [INFO]\t[TRAIN] Epoch=6/40, Step=75/129, loss=0.180088, acc1=1.000000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:10:16\n",
      "2023-06-02 16:13:31 [INFO]\t[TRAIN] Epoch=6/40, Step=85/129, loss=0.729699, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:51\n",
      "2023-06-02 16:13:32 [INFO]\t[TRAIN] Epoch=6/40, Step=95/129, loss=0.363866, acc1=0.937500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:52\n",
      "2023-06-02 16:13:33 [INFO]\t[TRAIN] Epoch=6/40, Step=105/129, loss=0.563625, acc1=0.750000, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:48\n",
      "2023-06-02 16:13:34 [INFO]\t[TRAIN] Epoch=6/40, Step=115/129, loss=0.404381, acc1=0.937500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:50\n",
      "2023-06-02 16:13:35 [INFO]\t[TRAIN] Epoch=6/40, Step=125/129, loss=0.218476, acc1=0.937500, acc5=1.000000, lr=0.005000, time_each_step=0.11s, eta=0:9:49\n",
      "2023-06-02 16:13:36 [INFO]\t[TRAIN] Epoch 6 finished, loss=0.42107973, acc1=0.8221899, acc5=1.0 .\n",
      "2023-06-02 16:13:36 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:13:36 [INFO]\t[EVAL] Finished, Epoch=6, acc1=0.823718, acc5=1.000000 .\n",
      "2023-06-02 16:13:39 [INFO]\tModel saved in output/resNet101_vd_ssld/best_model.\n",
      "2023-06-02 16:13:39 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, acc1=0.8237178921699524\n",
      "2023-06-02 16:13:41 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_6.\n",
      "2023-06-02 16:13:42 [INFO]\t[TRAIN] Epoch=7/40, Step=6/129, loss=0.155218, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.14s, eta=0:12:5\n",
      "2023-06-02 16:13:43 [INFO]\t[TRAIN] Epoch=7/40, Step=16/129, loss=0.142299, acc1=1.000000, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:9:14\n",
      "2023-06-02 16:13:44 [INFO]\t[TRAIN] Epoch=7/40, Step=26/129, loss=0.292106, acc1=0.875000, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:9:17\n",
      "2023-06-02 16:13:45 [INFO]\t[TRAIN] Epoch=7/40, Step=36/129, loss=0.285355, acc1=0.812500, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:9:22\n",
      "2023-06-02 16:13:46 [INFO]\t[TRAIN] Epoch=7/40, Step=46/129, loss=0.189173, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:9:16\n",
      "2023-06-02 16:13:47 [INFO]\t[TRAIN] Epoch=7/40, Step=56/129, loss=0.146763, acc1=1.000000, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:9:10\n",
      "2023-06-02 16:13:49 [INFO]\t[TRAIN] Epoch=7/40, Step=66/129, loss=0.151387, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:31\n",
      "2023-06-02 16:13:50 [INFO]\t[TRAIN] Epoch=7/40, Step=76/129, loss=0.364333, acc1=0.812500, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:31\n",
      "2023-06-02 16:13:51 [INFO]\t[TRAIN] Epoch=7/40, Step=86/129, loss=0.347458, acc1=0.812500, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:26\n",
      "2023-06-02 16:13:52 [INFO]\t[TRAIN] Epoch=7/40, Step=96/129, loss=0.412888, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:30\n",
      "2023-06-02 16:13:53 [INFO]\t[TRAIN] Epoch=7/40, Step=106/129, loss=0.321868, acc1=0.875000, acc5=1.000000, lr=0.000500, time_each_step=0.12s, eta=0:10:20\n",
      "2023-06-02 16:13:54 [INFO]\t[TRAIN] Epoch=7/40, Step=116/129, loss=0.236369, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:22\n",
      "2023-06-02 16:13:55 [INFO]\t[TRAIN] Epoch=7/40, Step=126/129, loss=0.279089, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:26\n",
      "2023-06-02 16:13:55 [INFO]\t[TRAIN] Epoch 7 finished, loss=0.28264263, acc1=0.89244187, acc5=1.0 .\n",
      "2023-06-02 16:13:56 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:13:56 [INFO]\t[EVAL] Finished, Epoch=7, acc1=0.870192, acc5=1.000000 .\n",
      "2023-06-02 16:13:59 [INFO]\tModel saved in output/resNet101_vd_ssld/best_model.\n",
      "2023-06-02 16:13:59 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_7, acc1=0.870192289352417\n",
      "2023-06-02 16:14:01 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_7.\n",
      "2023-06-02 16:14:03 [INFO]\t[TRAIN] Epoch=8/40, Step=7/129, loss=0.136382, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.14s, eta=0:11:49\n",
      "2023-06-02 16:14:04 [INFO]\t[TRAIN] Epoch=8/40, Step=17/129, loss=0.305878, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:9:5\n",
      "2023-06-02 16:14:05 [INFO]\t[TRAIN] Epoch=8/40, Step=27/129, loss=0.175515, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:8:59\n",
      "2023-06-02 16:14:06 [INFO]\t[TRAIN] Epoch=8/40, Step=37/129, loss=0.192108, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:8:55\n",
      "2023-06-02 16:14:07 [INFO]\t[TRAIN] Epoch=8/40, Step=47/129, loss=0.102442, acc1=1.000000, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:26\n",
      "2023-06-02 16:14:08 [INFO]\t[TRAIN] Epoch=8/40, Step=57/129, loss=0.044660, acc1=1.000000, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:23\n",
      "2023-06-02 16:14:09 [INFO]\t[TRAIN] Epoch=8/40, Step=67/129, loss=0.195970, acc1=0.875000, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:22\n",
      "2023-06-02 16:14:10 [INFO]\t[TRAIN] Epoch=8/40, Step=77/129, loss=0.086452, acc1=1.000000, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:17\n",
      "2023-06-02 16:14:11 [INFO]\t[TRAIN] Epoch=8/40, Step=87/129, loss=0.137662, acc1=1.000000, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:15\n",
      "2023-06-02 16:14:12 [INFO]\t[TRAIN] Epoch=8/40, Step=97/129, loss=0.241786, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:13\n",
      "2023-06-02 16:14:13 [INFO]\t[TRAIN] Epoch=8/40, Step=107/129, loss=0.144145, acc1=0.937500, acc5=1.000000, lr=0.000500, time_each_step=0.1s, eta=0:9:5\n",
      "2023-06-02 16:14:14 [INFO]\t[TRAIN] Epoch=8/40, Step=117/129, loss=0.367318, acc1=0.812500, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:8\n",
      "2023-06-02 16:14:15 [INFO]\t[TRAIN] Epoch=8/40, Step=127/129, loss=0.113962, acc1=1.000000, acc5=1.000000, lr=0.000500, time_each_step=0.11s, eta=0:9:12\n",
      "2023-06-02 16:14:16 [INFO]\t[TRAIN] Epoch 8 finished, loss=0.22794423, acc1=0.9084302, acc5=1.0 .\n",
      "2023-06-02 16:14:16 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:14:16 [INFO]\t[EVAL] Finished, Epoch=8, acc1=0.891026, acc5=1.000000 .\n",
      "2023-06-02 16:14:19 [INFO]\tModel saved in output/resNet101_vd_ssld/best_model.\n",
      "2023-06-02 16:14:19 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_8, acc1=0.8910256028175354\n",
      "2023-06-02 16:14:21 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_8.\n",
      "2023-06-02 16:14:23 [INFO]\t[TRAIN] Epoch=9/40, Step=8/129, loss=0.132159, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.15s, eta=0:11:42\n",
      "2023-06-02 16:14:24 [INFO]\t[TRAIN] Epoch=9/40, Step=18/129, loss=0.150931, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:9:22\n",
      "2023-06-02 16:14:25 [INFO]\t[TRAIN] Epoch=9/40, Step=28/129, loss=0.295571, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:9:2\n",
      "2023-06-02 16:14:26 [INFO]\t[TRAIN] Epoch=9/40, Step=38/129, loss=0.494321, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:9:13\n",
      "2023-06-02 16:14:27 [INFO]\t[TRAIN] Epoch=9/40, Step=48/129, loss=0.257853, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:9:10\n",
      "2023-06-02 16:14:28 [INFO]\t[TRAIN] Epoch=9/40, Step=58/129, loss=0.378919, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:9:1\n",
      "2023-06-02 16:14:29 [INFO]\t[TRAIN] Epoch=9/40, Step=68/129, loss=0.134039, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:9:11\n",
      "2023-06-02 16:14:30 [INFO]\t[TRAIN] Epoch=9/40, Step=78/129, loss=0.089807, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:9:7\n",
      "2023-06-02 16:14:31 [INFO]\t[TRAIN] Epoch=9/40, Step=88/129, loss=0.293074, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:9:2\n",
      "2023-06-02 16:14:32 [INFO]\t[TRAIN] Epoch=9/40, Step=98/129, loss=0.053664, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:8:58\n",
      "2023-06-02 16:14:33 [INFO]\t[TRAIN] Epoch=9/40, Step=108/129, loss=0.374318, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:8:58\n",
      "2023-06-02 16:14:35 [INFO]\t[TRAIN] Epoch=9/40, Step=118/129, loss=0.288947, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:8:54\n",
      "2023-06-02 16:14:36 [INFO]\t[TRAIN] Epoch=9/40, Step=128/129, loss=0.365878, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:8:57\n",
      "2023-06-02 16:14:36 [INFO]\t[TRAIN] Epoch 9 finished, loss=0.23756441, acc1=0.90552324, acc5=1.0 .\n",
      "2023-06-02 16:14:36 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:14:37 [INFO]\t[EVAL] Finished, Epoch=9, acc1=0.937500, acc5=1.000000 .\n",
      "2023-06-02 16:14:39 [INFO]\tModel saved in output/resNet101_vd_ssld/best_model.\n",
      "2023-06-02 16:14:39 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:14:42 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_9.\n",
      "2023-06-02 16:14:43 [INFO]\t[TRAIN] Epoch=10/40, Step=9/129, loss=0.119841, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:10:53\n",
      "2023-06-02 16:14:44 [INFO]\t[TRAIN] Epoch=10/40, Step=19/129, loss=0.403804, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:32\n",
      "2023-06-02 16:14:45 [INFO]\t[TRAIN] Epoch=10/40, Step=29/129, loss=0.224476, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:36\n",
      "2023-06-02 16:14:46 [INFO]\t[TRAIN] Epoch=10/40, Step=39/129, loss=0.260085, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:21\n",
      "2023-06-02 16:14:47 [INFO]\t[TRAIN] Epoch=10/40, Step=49/129, loss=0.226606, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:32\n",
      "2023-06-02 16:14:48 [INFO]\t[TRAIN] Epoch=10/40, Step=59/129, loss=0.281772, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:31\n",
      "2023-06-02 16:14:49 [INFO]\t[TRAIN] Epoch=10/40, Step=69/129, loss=0.078601, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:35\n",
      "2023-06-02 16:14:50 [INFO]\t[TRAIN] Epoch=10/40, Step=79/129, loss=0.401542, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:30\n",
      "2023-06-02 16:14:51 [INFO]\t[TRAIN] Epoch=10/40, Step=89/129, loss=0.191323, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:26\n",
      "2023-06-02 16:14:52 [INFO]\t[TRAIN] Epoch=10/40, Step=99/129, loss=0.220499, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:32\n",
      "2023-06-02 16:14:53 [INFO]\t[TRAIN] Epoch=10/40, Step=109/129, loss=0.711936, acc1=0.687500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:30\n",
      "2023-06-02 16:14:54 [INFO]\t[TRAIN] Epoch=10/40, Step=119/129, loss=0.252832, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:26\n",
      "2023-06-02 16:14:55 [INFO]\t[TRAIN] Epoch=10/40, Step=129/129, loss=0.149650, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:8:20\n",
      "2023-06-02 16:14:56 [INFO]\t[TRAIN] Epoch 10 finished, loss=0.23366132, acc1=0.9103682, acc5=1.0 .\n",
      "2023-06-02 16:14:56 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:14:56 [INFO]\t[EVAL] Finished, Epoch=10, acc1=0.911859, acc5=1.000000 .\n",
      "2023-06-02 16:14:56 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:14:59 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_10.\n",
      "2023-06-02 16:15:00 [INFO]\t[TRAIN] Epoch=11/40, Step=10/129, loss=0.107474, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.15s, eta=0:10:8\n",
      "2023-06-02 16:15:01 [INFO]\t[TRAIN] Epoch=11/40, Step=20/129, loss=0.336571, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:13\n",
      "2023-06-02 16:15:02 [INFO]\t[TRAIN] Epoch=11/40, Step=30/129, loss=0.095246, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:8\n",
      "2023-06-02 16:15:03 [INFO]\t[TRAIN] Epoch=11/40, Step=40/129, loss=0.353809, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:4\n",
      "2023-06-02 16:15:05 [INFO]\t[TRAIN] Epoch=11/40, Step=50/129, loss=0.321000, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:6\n",
      "2023-06-02 16:15:06 [INFO]\t[TRAIN] Epoch=11/40, Step=60/129, loss=0.116634, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:10\n",
      "2023-06-02 16:15:07 [INFO]\t[TRAIN] Epoch=11/40, Step=70/129, loss=0.264639, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:3\n",
      "2023-06-02 16:15:08 [INFO]\t[TRAIN] Epoch=11/40, Step=80/129, loss=0.093631, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:6\n",
      "2023-06-02 16:15:09 [INFO]\t[TRAIN] Epoch=11/40, Step=90/129, loss=0.086795, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:10\n",
      "2023-06-02 16:15:10 [INFO]\t[TRAIN] Epoch=11/40, Step=100/129, loss=0.441202, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:11\n",
      "2023-06-02 16:15:11 [INFO]\t[TRAIN] Epoch=11/40, Step=110/129, loss=0.192253, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:1\n",
      "2023-06-02 16:15:12 [INFO]\t[TRAIN] Epoch=11/40, Step=120/129, loss=0.151856, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:58\n",
      "2023-06-02 16:15:13 [INFO]\t[TRAIN] Epoch 11 finished, loss=0.23504724, acc1=0.9001938, acc5=1.0 .\n",
      "2023-06-02 16:15:13 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:15:14 [INFO]\t[EVAL] Finished, Epoch=11, acc1=0.911859, acc5=1.000000 .\n",
      "2023-06-02 16:15:14 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:15:16 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_11.\n",
      "2023-06-02 16:15:17 [INFO]\t[TRAIN] Epoch=12/40, Step=1/129, loss=0.291279, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:9:4\n",
      "2023-06-02 16:15:18 [INFO]\t[TRAIN] Epoch=12/40, Step=11/129, loss=0.135640, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:48\n",
      "2023-06-02 16:15:19 [INFO]\t[TRAIN] Epoch=12/40, Step=21/129, loss=0.226653, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:40\n",
      "2023-06-02 16:15:20 [INFO]\t[TRAIN] Epoch=12/40, Step=31/129, loss=0.256200, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:39\n",
      "2023-06-02 16:15:21 [INFO]\t[TRAIN] Epoch=12/40, Step=41/129, loss=0.082264, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:39\n",
      "2023-06-02 16:15:22 [INFO]\t[TRAIN] Epoch=12/40, Step=51/129, loss=0.317506, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:35\n",
      "2023-06-02 16:15:23 [INFO]\t[TRAIN] Epoch=12/40, Step=61/129, loss=0.192023, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:43\n",
      "2023-06-02 16:15:24 [INFO]\t[TRAIN] Epoch=12/40, Step=71/129, loss=0.382455, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:2\n",
      "2023-06-02 16:15:25 [INFO]\t[TRAIN] Epoch=12/40, Step=81/129, loss=0.146772, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:32\n",
      "2023-06-02 16:15:26 [INFO]\t[TRAIN] Epoch=12/40, Step=91/129, loss=0.145300, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:30\n",
      "2023-06-02 16:15:27 [INFO]\t[TRAIN] Epoch=12/40, Step=101/129, loss=0.098633, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:7:1\n",
      "2023-06-02 16:15:28 [INFO]\t[TRAIN] Epoch=12/40, Step=111/129, loss=0.194801, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:53\n",
      "2023-06-02 16:15:29 [INFO]\t[TRAIN] Epoch=12/40, Step=121/129, loss=0.051180, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:52\n",
      "2023-06-02 16:15:30 [INFO]\t[TRAIN] Epoch 12 finished, loss=0.231323, acc1=0.9142442, acc5=1.0 .\n",
      "2023-06-02 16:15:30 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:15:31 [INFO]\t[EVAL] Finished, Epoch=12, acc1=0.891026, acc5=1.000000 .\n",
      "2023-06-02 16:15:31 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:15:34 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_12.\n",
      "2023-06-02 16:15:34 [INFO]\t[TRAIN] Epoch=13/40, Step=2/129, loss=0.936329, acc1=0.625000, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:8:58\n",
      "2023-06-02 16:15:35 [INFO]\t[TRAIN] Epoch=13/40, Step=12/129, loss=0.089364, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:41\n",
      "2023-06-02 16:15:36 [INFO]\t[TRAIN] Epoch=13/40, Step=22/129, loss=0.273544, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:54\n",
      "2023-06-02 16:15:37 [INFO]\t[TRAIN] Epoch=13/40, Step=32/129, loss=0.179741, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:42\n",
      "2023-06-02 16:15:38 [INFO]\t[TRAIN] Epoch=13/40, Step=42/129, loss=0.138142, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:41\n",
      "2023-06-02 16:15:39 [INFO]\t[TRAIN] Epoch=13/40, Step=52/129, loss=0.087943, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:43\n",
      "2023-06-02 16:15:41 [INFO]\t[TRAIN] Epoch=13/40, Step=62/129, loss=0.130788, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:41\n",
      "2023-06-02 16:15:42 [INFO]\t[TRAIN] Epoch=13/40, Step=72/129, loss=0.221934, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:6:30\n",
      "2023-06-02 16:15:43 [INFO]\t[TRAIN] Epoch=13/40, Step=82/129, loss=0.098867, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:39\n",
      "2023-06-02 16:15:44 [INFO]\t[TRAIN] Epoch=13/40, Step=92/129, loss=0.150947, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:35\n",
      "2023-06-02 16:15:45 [INFO]\t[TRAIN] Epoch=13/40, Step=102/129, loss=0.201384, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:53\n",
      "2023-06-02 16:15:46 [INFO]\t[TRAIN] Epoch=13/40, Step=112/129, loss=0.173688, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:36\n",
      "2023-06-02 16:15:47 [INFO]\t[TRAIN] Epoch=13/40, Step=122/129, loss=0.207062, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:32\n",
      "2023-06-02 16:15:48 [INFO]\t[TRAIN] Epoch 13 finished, loss=0.21819846, acc1=0.91812015, acc5=1.0 .\n",
      "2023-06-02 16:15:48 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:15:49 [INFO]\t[EVAL] Finished, Epoch=13, acc1=0.937500, acc5=1.000000 .\n",
      "2023-06-02 16:15:49 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:15:51 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_13.\n",
      "2023-06-02 16:15:52 [INFO]\t[TRAIN] Epoch=14/40, Step=3/129, loss=0.311141, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:8:39\n",
      "2023-06-02 16:15:53 [INFO]\t[TRAIN] Epoch=14/40, Step=13/129, loss=0.301944, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:31\n",
      "2023-06-02 16:15:54 [INFO]\t[TRAIN] Epoch=14/40, Step=23/129, loss=0.118322, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:30\n",
      "2023-06-02 16:15:55 [INFO]\t[TRAIN] Epoch=14/40, Step=33/129, loss=0.063737, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:26\n",
      "2023-06-02 16:15:56 [INFO]\t[TRAIN] Epoch=14/40, Step=43/129, loss=0.139344, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:27\n",
      "2023-06-02 16:15:57 [INFO]\t[TRAIN] Epoch=14/40, Step=53/129, loss=0.088149, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:29\n",
      "2023-06-02 16:15:58 [INFO]\t[TRAIN] Epoch=14/40, Step=63/129, loss=0.496488, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:23\n",
      "2023-06-02 16:15:59 [INFO]\t[TRAIN] Epoch=14/40, Step=73/129, loss=0.147143, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:23\n",
      "2023-06-02 16:16:00 [INFO]\t[TRAIN] Epoch=14/40, Step=83/129, loss=0.136650, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:34\n",
      "2023-06-02 16:16:01 [INFO]\t[TRAIN] Epoch=14/40, Step=93/129, loss=0.436211, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:44\n",
      "2023-06-02 16:16:03 [INFO]\t[TRAIN] Epoch=14/40, Step=103/129, loss=0.165151, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:20\n",
      "2023-06-02 16:16:04 [INFO]\t[TRAIN] Epoch=14/40, Step=113/129, loss=0.073663, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:23\n",
      "2023-06-02 16:16:05 [INFO]\t[TRAIN] Epoch=14/40, Step=123/129, loss=0.428895, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:19\n",
      "2023-06-02 16:16:05 [INFO]\t[TRAIN] Epoch 14 finished, loss=0.21883163, acc1=0.91812015, acc5=1.0 .\n",
      "2023-06-02 16:16:06 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:16:06 [INFO]\t[EVAL] Finished, Epoch=14, acc1=0.911859, acc5=1.000000 .\n",
      "2023-06-02 16:16:06 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:16:09 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_14.\n",
      "2023-06-02 16:16:09 [INFO]\t[TRAIN] Epoch=15/40, Step=4/129, loss=0.191322, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:8:21\n",
      "2023-06-02 16:16:11 [INFO]\t[TRAIN] Epoch=15/40, Step=14/129, loss=0.446955, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:20\n",
      "2023-06-02 16:16:12 [INFO]\t[TRAIN] Epoch=15/40, Step=24/129, loss=0.335486, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:16\n",
      "2023-06-02 16:16:13 [INFO]\t[TRAIN] Epoch=15/40, Step=34/129, loss=0.147422, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:15\n",
      "2023-06-02 16:16:14 [INFO]\t[TRAIN] Epoch=15/40, Step=44/129, loss=0.368478, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:11\n",
      "2023-06-02 16:16:15 [INFO]\t[TRAIN] Epoch=15/40, Step=54/129, loss=0.121211, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:15\n",
      "2023-06-02 16:16:16 [INFO]\t[TRAIN] Epoch=15/40, Step=64/129, loss=0.163415, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:11\n",
      "2023-06-02 16:16:17 [INFO]\t[TRAIN] Epoch=15/40, Step=74/129, loss=0.148301, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:6\n",
      "2023-06-02 16:16:18 [INFO]\t[TRAIN] Epoch=15/40, Step=84/129, loss=0.046451, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:48\n",
      "2023-06-02 16:16:19 [INFO]\t[TRAIN] Epoch=15/40, Step=94/129, loss=0.594217, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:9\n",
      "2023-06-02 16:16:20 [INFO]\t[TRAIN] Epoch=15/40, Step=104/129, loss=0.343613, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:5\n",
      "2023-06-02 16:16:21 [INFO]\t[TRAIN] Epoch=15/40, Step=114/129, loss=0.288623, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:9\n",
      "2023-06-02 16:16:22 [INFO]\t[TRAIN] Epoch=15/40, Step=124/129, loss=0.243811, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:7\n",
      "2023-06-02 16:16:23 [INFO]\t[TRAIN] Epoch 15 finished, loss=0.2330113, acc1=0.90358526, acc5=1.0 .\n",
      "2023-06-02 16:16:23 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:16:24 [INFO]\t[EVAL] Finished, Epoch=15, acc1=0.891026, acc5=1.000000 .\n",
      "2023-06-02 16:16:24 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:16:26 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_15.\n",
      "2023-06-02 16:16:27 [INFO]\t[TRAIN] Epoch=16/40, Step=5/129, loss=0.355196, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:7:45\n",
      "2023-06-02 16:16:28 [INFO]\t[TRAIN] Epoch=16/40, Step=15/129, loss=0.059969, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:45\n",
      "2023-06-02 16:16:29 [INFO]\t[TRAIN] Epoch=16/40, Step=25/129, loss=0.301340, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:46\n",
      "2023-06-02 16:16:30 [INFO]\t[TRAIN] Epoch=16/40, Step=35/129, loss=0.376800, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:54\n",
      "2023-06-02 16:16:31 [INFO]\t[TRAIN] Epoch=16/40, Step=45/129, loss=0.216545, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:45\n",
      "2023-06-02 16:16:32 [INFO]\t[TRAIN] Epoch=16/40, Step=55/129, loss=0.617490, acc1=0.625000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:49\n",
      "2023-06-02 16:16:33 [INFO]\t[TRAIN] Epoch=16/40, Step=65/129, loss=0.232766, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:43\n",
      "2023-06-02 16:16:34 [INFO]\t[TRAIN] Epoch=16/40, Step=75/129, loss=0.161188, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:44\n",
      "2023-06-02 16:16:35 [INFO]\t[TRAIN] Epoch=16/40, Step=85/129, loss=0.591970, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:39\n",
      "2023-06-02 16:16:36 [INFO]\t[TRAIN] Epoch=16/40, Step=95/129, loss=0.733007, acc1=0.625000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:38\n",
      "2023-06-02 16:16:37 [INFO]\t[TRAIN] Epoch=16/40, Step=105/129, loss=0.289461, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:34\n",
      "2023-06-02 16:16:38 [INFO]\t[TRAIN] Epoch=16/40, Step=115/129, loss=0.164059, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:35\n",
      "2023-06-02 16:16:39 [INFO]\t[TRAIN] Epoch=16/40, Step=125/129, loss=0.223547, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:39\n",
      "2023-06-02 16:16:40 [INFO]\t[TRAIN] Epoch 16 finished, loss=0.22866607, acc1=0.90358526, acc5=1.0 .\n",
      "2023-06-02 16:16:40 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:16:41 [INFO]\t[EVAL] Finished, Epoch=16, acc1=0.911859, acc5=1.000000 .\n",
      "2023-06-02 16:16:41 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:16:43 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_16.\n",
      "2023-06-02 16:16:44 [INFO]\t[TRAIN] Epoch=17/40, Step=6/129, loss=0.136672, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:7:33\n",
      "2023-06-02 16:16:45 [INFO]\t[TRAIN] Epoch=17/40, Step=16/129, loss=0.111081, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:35\n",
      "2023-06-02 16:16:46 [INFO]\t[TRAIN] Epoch=17/40, Step=26/129, loss=0.231760, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:29\n",
      "2023-06-02 16:16:47 [INFO]\t[TRAIN] Epoch=17/40, Step=36/129, loss=0.283815, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:46\n",
      "2023-06-02 16:16:48 [INFO]\t[TRAIN] Epoch=17/40, Step=46/129, loss=0.120652, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:43\n",
      "2023-06-02 16:16:49 [INFO]\t[TRAIN] Epoch=17/40, Step=56/129, loss=0.130700, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:43\n",
      "2023-06-02 16:16:50 [INFO]\t[TRAIN] Epoch=17/40, Step=66/129, loss=0.280428, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:39\n",
      "2023-06-02 16:16:52 [INFO]\t[TRAIN] Epoch=17/40, Step=76/129, loss=0.133468, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:40\n",
      "2023-06-02 16:16:53 [INFO]\t[TRAIN] Epoch=17/40, Step=86/129, loss=0.334052, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:41\n",
      "2023-06-02 16:16:54 [INFO]\t[TRAIN] Epoch=17/40, Step=96/129, loss=0.149750, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:35\n",
      "2023-06-02 16:16:55 [INFO]\t[TRAIN] Epoch=17/40, Step=106/129, loss=0.109813, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:37\n",
      "2023-06-02 16:16:56 [INFO]\t[TRAIN] Epoch=17/40, Step=116/129, loss=0.487134, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:38\n",
      "2023-06-02 16:16:57 [INFO]\t[TRAIN] Epoch=17/40, Step=126/129, loss=0.133489, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:35\n",
      "2023-06-02 16:16:57 [INFO]\t[TRAIN] Epoch 17 finished, loss=0.22677216, acc1=0.91085273, acc5=1.0 .\n",
      "2023-06-02 16:16:58 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:16:58 [INFO]\t[EVAL] Finished, Epoch=17, acc1=0.932692, acc5=1.000000 .\n",
      "2023-06-02 16:16:58 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_9, acc1=0.9375\n",
      "2023-06-02 16:17:01 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_17.\n",
      "2023-06-02 16:17:02 [INFO]\t[TRAIN] Epoch=18/40, Step=7/129, loss=0.170015, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:7:15\n",
      "2023-06-02 16:17:03 [INFO]\t[TRAIN] Epoch=18/40, Step=17/129, loss=0.105090, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:18\n",
      "2023-06-02 16:17:04 [INFO]\t[TRAIN] Epoch=18/40, Step=27/129, loss=0.316155, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:22\n",
      "2023-06-02 16:17:05 [INFO]\t[TRAIN] Epoch=18/40, Step=37/129, loss=0.113941, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:46\n",
      "2023-06-02 16:17:06 [INFO]\t[TRAIN] Epoch=18/40, Step=47/129, loss=0.454950, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:28\n",
      "2023-06-02 16:17:07 [INFO]\t[TRAIN] Epoch=18/40, Step=57/129, loss=0.233691, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:28\n",
      "2023-06-02 16:17:08 [INFO]\t[TRAIN] Epoch=18/40, Step=67/129, loss=0.280809, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:29\n",
      "2023-06-02 16:17:09 [INFO]\t[TRAIN] Epoch=18/40, Step=77/129, loss=0.159085, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:26\n",
      "2023-06-02 16:17:10 [INFO]\t[TRAIN] Epoch=18/40, Step=87/129, loss=0.677343, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:27\n",
      "2023-06-02 16:17:11 [INFO]\t[TRAIN] Epoch=18/40, Step=97/129, loss=0.130951, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:23\n",
      "2023-06-02 16:17:13 [INFO]\t[TRAIN] Epoch=18/40, Step=107/129, loss=0.160872, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:25\n",
      "2023-06-02 16:17:14 [INFO]\t[TRAIN] Epoch=18/40, Step=117/129, loss=0.165036, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:26\n",
      "2023-06-02 16:17:15 [INFO]\t[TRAIN] Epoch=18/40, Step=127/129, loss=0.126568, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:35\n",
      "2023-06-02 16:17:15 [INFO]\t[TRAIN] Epoch 18 finished, loss=0.21137436, acc1=0.9132752, acc5=1.0 .\n",
      "2023-06-02 16:17:15 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:17:16 [INFO]\t[EVAL] Finished, Epoch=18, acc1=0.958333, acc5=1.000000 .\n",
      "2023-06-02 16:17:18 [INFO]\tModel saved in output/resNet101_vd_ssld/best_model.\n",
      "2023-06-02 16:17:18 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_18, acc1=0.9583333134651184\n",
      "2023-06-02 16:17:21 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_18.\n",
      "2023-06-02 16:17:22 [INFO]\t[TRAIN] Epoch=19/40, Step=8/129, loss=0.077241, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:7:45\n",
      "2023-06-02 16:17:23 [INFO]\t[TRAIN] Epoch=19/40, Step=18/129, loss=0.261028, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:57\n",
      "2023-06-02 16:17:24 [INFO]\t[TRAIN] Epoch=19/40, Step=28/129, loss=0.458696, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:58\n",
      "2023-06-02 16:17:25 [INFO]\t[TRAIN] Epoch=19/40, Step=38/129, loss=0.220370, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:54\n",
      "2023-06-02 16:17:26 [INFO]\t[TRAIN] Epoch=19/40, Step=48/129, loss=0.030064, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:54\n",
      "2023-06-02 16:17:27 [INFO]\t[TRAIN] Epoch=19/40, Step=58/129, loss=0.380926, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:59\n",
      "2023-06-02 16:17:28 [INFO]\t[TRAIN] Epoch=19/40, Step=68/129, loss=0.405892, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:52\n",
      "2023-06-02 16:17:29 [INFO]\t[TRAIN] Epoch=19/40, Step=78/129, loss=0.091608, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:52\n",
      "2023-06-02 16:17:30 [INFO]\t[TRAIN] Epoch=19/40, Step=88/129, loss=0.305620, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:56\n",
      "2023-06-02 16:17:31 [INFO]\t[TRAIN] Epoch=19/40, Step=98/129, loss=0.032230, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:5:49\n",
      "2023-06-02 16:17:32 [INFO]\t[TRAIN] Epoch=19/40, Step=108/129, loss=0.127753, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:9\n",
      "2023-06-02 16:17:34 [INFO]\t[TRAIN] Epoch=19/40, Step=118/129, loss=0.334434, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:7\n",
      "2023-06-02 16:17:35 [INFO]\t[TRAIN] Epoch=19/40, Step=128/129, loss=0.238350, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:6:4\n",
      "2023-06-02 16:17:35 [INFO]\t[TRAIN] Epoch 19 finished, loss=0.21371007, acc1=0.91521317, acc5=1.0 .\n",
      "2023-06-02 16:17:35 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:17:36 [INFO]\t[EVAL] Finished, Epoch=19, acc1=0.932692, acc5=1.000000 .\n",
      "2023-06-02 16:17:36 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_18, acc1=0.9583333134651184\n",
      "2023-06-02 16:17:38 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_19.\n",
      "2023-06-02 16:17:39 [INFO]\t[TRAIN] Epoch=20/40, Step=9/129, loss=0.481436, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:6:29\n",
      "2023-06-02 16:17:41 [INFO]\t[TRAIN] Epoch=20/40, Step=19/129, loss=0.254829, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:0\n",
      "2023-06-02 16:17:42 [INFO]\t[TRAIN] Epoch=20/40, Step=29/129, loss=0.110201, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:9\n",
      "2023-06-02 16:17:43 [INFO]\t[TRAIN] Epoch=20/40, Step=39/129, loss=0.371769, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:5\n",
      "2023-06-02 16:17:44 [INFO]\t[TRAIN] Epoch=20/40, Step=49/129, loss=0.042250, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:1\n",
      "2023-06-02 16:17:45 [INFO]\t[TRAIN] Epoch=20/40, Step=59/129, loss=0.287485, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:5:6\n",
      "2023-06-02 16:17:46 [INFO]\t[TRAIN] Epoch=20/40, Step=69/129, loss=0.121595, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:59\n",
      "2023-06-02 16:17:47 [INFO]\t[TRAIN] Epoch=20/40, Step=79/129, loss=0.132606, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:55\n",
      "2023-06-02 16:17:48 [INFO]\t[TRAIN] Epoch=20/40, Step=89/129, loss=0.105053, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:55\n",
      "2023-06-02 16:17:49 [INFO]\t[TRAIN] Epoch=20/40, Step=99/129, loss=0.103662, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:53\n",
      "2023-06-02 16:17:50 [INFO]\t[TRAIN] Epoch=20/40, Step=109/129, loss=0.184979, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:54\n",
      "2023-06-02 16:17:51 [INFO]\t[TRAIN] Epoch=20/40, Step=119/129, loss=0.084861, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:51\n",
      "2023-06-02 16:17:52 [INFO]\t[TRAIN] Epoch=20/40, Step=129/129, loss=0.155976, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:51\n",
      "2023-06-02 16:17:52 [INFO]\t[TRAIN] Epoch 20 finished, loss=0.19749232, acc1=0.9142442, acc5=1.0 .\n",
      "2023-06-02 16:17:53 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:17:53 [INFO]\t[EVAL] Finished, Epoch=20, acc1=0.958333, acc5=1.000000 .\n",
      "2023-06-02 16:17:53 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_18, acc1=0.9583333134651184\n",
      "2023-06-02 16:17:56 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_20.\n",
      "2023-06-02 16:17:57 [INFO]\t[TRAIN] Epoch=21/40, Step=10/129, loss=0.139713, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.15s, eta=0:6:29\n",
      "2023-06-02 16:17:58 [INFO]\t[TRAIN] Epoch=21/40, Step=20/129, loss=0.059666, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:52\n",
      "2023-06-02 16:17:59 [INFO]\t[TRAIN] Epoch=21/40, Step=30/129, loss=0.087901, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:50\n",
      "2023-06-02 16:18:00 [INFO]\t[TRAIN] Epoch=21/40, Step=40/129, loss=0.135454, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:53\n",
      "2023-06-02 16:18:01 [INFO]\t[TRAIN] Epoch=21/40, Step=50/129, loss=0.143642, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:48\n",
      "2023-06-02 16:18:02 [INFO]\t[TRAIN] Epoch=21/40, Step=60/129, loss=0.530329, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:46\n",
      "2023-06-02 16:18:04 [INFO]\t[TRAIN] Epoch=21/40, Step=70/129, loss=0.269942, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:42\n",
      "2023-06-02 16:18:05 [INFO]\t[TRAIN] Epoch=21/40, Step=80/129, loss=0.059201, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:43\n",
      "2023-06-02 16:18:06 [INFO]\t[TRAIN] Epoch=21/40, Step=90/129, loss=0.208569, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:43\n",
      "2023-06-02 16:18:07 [INFO]\t[TRAIN] Epoch=21/40, Step=100/129, loss=0.290637, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:52\n",
      "2023-06-02 16:18:08 [INFO]\t[TRAIN] Epoch=21/40, Step=110/129, loss=0.429693, acc1=0.687500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:43\n",
      "2023-06-02 16:18:09 [INFO]\t[TRAIN] Epoch=21/40, Step=120/129, loss=0.100755, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:37\n",
      "2023-06-02 16:18:10 [INFO]\t[TRAIN] Epoch 21 finished, loss=0.19699399, acc1=0.92248064, acc5=1.0 .\n",
      "2023-06-02 16:18:10 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:18:11 [INFO]\t[EVAL] Finished, Epoch=21, acc1=0.932692, acc5=1.000000 .\n",
      "2023-06-02 16:18:11 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_18, acc1=0.9583333134651184\n",
      "2023-06-02 16:18:14 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_21.\n",
      "2023-06-02 16:18:14 [INFO]\t[TRAIN] Epoch=22/40, Step=1/129, loss=0.106948, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:6:8\n",
      "2023-06-02 16:18:15 [INFO]\t[TRAIN] Epoch=22/40, Step=11/129, loss=0.195495, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:28\n",
      "2023-06-02 16:18:16 [INFO]\t[TRAIN] Epoch=22/40, Step=21/129, loss=0.114873, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:28\n",
      "2023-06-02 16:18:17 [INFO]\t[TRAIN] Epoch=22/40, Step=31/129, loss=0.316651, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:19\n",
      "2023-06-02 16:18:18 [INFO]\t[TRAIN] Epoch=22/40, Step=41/129, loss=0.099156, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:18\n",
      "2023-06-02 16:18:19 [INFO]\t[TRAIN] Epoch=22/40, Step=51/129, loss=0.396788, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:19\n",
      "2023-06-02 16:18:20 [INFO]\t[TRAIN] Epoch=22/40, Step=61/129, loss=0.121758, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:18\n",
      "2023-06-02 16:18:21 [INFO]\t[TRAIN] Epoch=22/40, Step=71/129, loss=0.093060, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:18\n",
      "2023-06-02 16:18:22 [INFO]\t[TRAIN] Epoch=22/40, Step=81/129, loss=0.295011, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:22\n",
      "2023-06-02 16:18:23 [INFO]\t[TRAIN] Epoch=22/40, Step=91/129, loss=0.197239, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:12\n",
      "2023-06-02 16:18:24 [INFO]\t[TRAIN] Epoch=22/40, Step=101/129, loss=0.189742, acc1=0.812500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:11\n",
      "2023-06-02 16:18:25 [INFO]\t[TRAIN] Epoch=22/40, Step=111/129, loss=0.169895, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:11\n",
      "2023-06-02 16:18:26 [INFO]\t[TRAIN] Epoch=22/40, Step=121/129, loss=0.159786, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.1s, eta=0:4:8\n",
      "2023-06-02 16:18:27 [INFO]\t[TRAIN] Epoch 22 finished, loss=0.21080106, acc1=0.9147287, acc5=1.0 .\n",
      "2023-06-02 16:18:27 [INFO]\tStart to evaluate(total_samples=45, total_steps=3)...\n",
      "2023-06-02 16:18:28 [INFO]\t[EVAL] Finished, Epoch=22, acc1=0.932692, acc5=1.000000 .\n",
      "2023-06-02 16:18:28 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_18, acc1=0.9583333134651184\n",
      "2023-06-02 16:18:29 [INFO]\tModel saved in output/resNet101_vd_ssld/epoch_22.\n",
      "2023-06-02 16:18:29 [INFO]\t[TRAIN] Epoch=23/40, Step=2/129, loss=0.178405, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.14s, eta=0:5:44\n",
      "2023-06-02 16:18:30 [INFO]\t[TRAIN] Epoch=23/40, Step=12/129, loss=0.125095, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:23\n",
      "2023-06-02 16:18:31 [INFO]\t[TRAIN] Epoch=23/40, Step=22/129, loss=0.202954, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:22\n",
      "2023-06-02 16:18:32 [INFO]\t[TRAIN] Epoch=23/40, Step=32/129, loss=0.202546, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:22\n",
      "2023-06-02 16:18:34 [INFO]\t[TRAIN] Epoch=23/40, Step=42/129, loss=0.449877, acc1=0.875000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:20\n",
      "2023-06-02 16:18:35 [INFO]\t[TRAIN] Epoch=23/40, Step=52/129, loss=0.076794, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:14\n",
      "2023-06-02 16:18:36 [INFO]\t[TRAIN] Epoch=23/40, Step=62/129, loss=0.027155, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:10\n",
      "2023-06-02 16:18:37 [INFO]\t[TRAIN] Epoch=23/40, Step=72/129, loss=0.113097, acc1=1.000000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:16\n",
      "2023-06-02 16:18:38 [INFO]\t[TRAIN] Epoch=23/40, Step=82/129, loss=0.440369, acc1=0.750000, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:10\n",
      "2023-06-02 16:18:39 [INFO]\t[TRAIN] Epoch=23/40, Step=92/129, loss=0.243519, acc1=0.937500, acc5=1.000000, lr=0.000050, time_each_step=0.11s, eta=0:4:10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1951/2160958234.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output/resNet101_vd_ssld'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             use_vdl=True)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_epochs, train_dataset, train_batch_size, eval_dataset, optimizer, save_interval_epochs, log_interval_steps, save_dir, pretrain_weights, learning_rate, warmup_steps, warmup_start_lr, lr_decay_epochs, lr_decay_gamma, early_stop, early_stop_patience, use_vdl, resume_checkpoint)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mearly_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mearly_stop_patience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_patience\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             use_vdl=use_vdl)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     def quant_aware_train(self,\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/models/base.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, num_epochs, train_dataset, train_batch_size, eval_dataset, save_interval_epochs, log_interval_steps, save_dir, ema, early_stop, early_stop_patience, use_vdl)\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-338>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_switch_tracer_mode_guard_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-336>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/wrapped_decorator.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         assert in_dygraph_mode(\n\u001b[1;32m    228\u001b[0m         ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             self._apply_optimize(\n\u001b[0;32m-> 1136\u001b[0;31m                 loss=None, startup_program=None, params_grads=params_grads)\n\u001b[0m\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_apply_optimize\u001b[0;34m(self, loss, startup_program, params_grads)\u001b[0m\n\u001b[1;32m    889\u001b[0m                     params_grads['params'] = self.append_regularization_ops(\n\u001b[1;32m    890\u001b[0m                         params_grads['params'], self.regularization)\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0moptimize_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_optimization_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mprogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_create_optimization_pass\u001b[0;34m(self, parameters_and_grads)\u001b[0m\n\u001b[1;32m    694\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mparam_and_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_append_optimize_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_and_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mparam_and_grad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters_and_grads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/momentum.py\u001b[0m in \u001b[0;36m_append_optimize_op\u001b[0;34m(self, block, param_and_grad)\u001b[0m\n\u001b[1;32m    285\u001b[0m         velocity_acc = self._get_accumulator(self._velocity_acc_str,\n\u001b[1;32m    286\u001b[0m                                              param_and_grad[0])\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_param_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_and_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0;31m# For fusion of momentum and l2decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_create_param_lr\u001b[0;34m(self, param_and_grad)\u001b[0m\n\u001b[1;32m    515\u001b[0m                             \u001b[0mis_with_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                                 'scale_with_param_lr'):\n\u001b[0;32m--> 517\u001b[0;31m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mparam_lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(self, other_var)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;31m# but only +, -, *, / can use this method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mscalar_method\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mscalar_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0;31m# in all cases(+, -, *, /, **, //, %), we can cast it to float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py\u001b[0m in \u001b[0;36m_scalar_mul_\u001b[0;34m(var, value)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_scalar_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_scalar_elementwise_op_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_scalar_div_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py\u001b[0m in \u001b[0;36m_scalar_elementwise_op_\u001b[0;34m(var, scale, bias)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_scalar_elementwise_op_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_C_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_neg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = pdx.datasets.ImageNet(\n",
    "    data_dir='/home/aistudio/data/dataset/face_data_5/face_image_train',\n",
    "    file_list='/home/aistudio/train.txt',\n",
    "    label_list='/home/aistudio/label.txt',\n",
    "    transforms=train_transforms,\n",
    "    shuffle=True)\n",
    "    \n",
    "eval_dataset = pdx.datasets.ImageNet(\n",
    "    data_dir='/home/aistudio/data/dataset/face_data_5/face_image_train',\n",
    "    file_list='/home/aistudio/eval.txt',\n",
    "    label_list='/home/aistudio/label.txt',\n",
    "    transforms=eval_transforms)\n",
    "print(len(train_dataset.labels))\n",
    "num_classes = 6\n",
    "model = pdx.cls.ResNet101_vd_ssld(num_classes=num_classes)\n",
    "model.train(num_epochs=40,\n",
    "            train_dataset=train_dataset,\n",
    "            train_batch_size=16,\n",
    "            eval_dataset=eval_dataset,\n",
    "            lr_decay_epochs=[6, 8],\n",
    "            save_interval_epochs=1,\n",
    "            learning_rate=0.005,\n",
    "            save_dir='output/resNet101_vd_ssld',\n",
    "            use_vdl=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-02 16:18:44 [INFO]\tModel[ResNet101_vd_ssld] loaded.\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.96996146}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.67866117}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.99237895}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.99883837}]\n",
      "[{'category_id': 4, 'category': '5', 'score': 0.544641}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.90058976}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.592996}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.96648484}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.9766209}]\n",
      "[{'category_id': 4, 'category': '5', 'score': 0.86921006}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.97990555}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.97254163}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.8372049}]\n",
      "[{'category_id': 4, 'category': '5', 'score': 0.5568044}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.992937}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.6102291}]\n",
      "[{'category_id': 4, 'category': '5', 'score': 0.9766629}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.96277314}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.83087194}]\n",
      "[{'category_id': 4, 'category': '5', 'score': 0.84549344}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.9999865}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.7778472}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.9834035}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.9265653}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.9920676}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.94385356}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.996988}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.59870607}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.99027306}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.8241746}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.98003525}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.70579386}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.95950645}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.99888533}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.99792576}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.7232764}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-201:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 583, in _get_data\n",
      "    data = self._data_queue.get(timeout=self._timeout)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/multiprocessing/queues.py\", line 105, in get\n",
      "    raise Empty\n",
      "_queue.Empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 505, in _thread_loop\n",
      "    batch = self._get_data()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 599, in _get_data\n",
      "    \"pids: {}\".format(len(failed_workers), pids))\n",
      "RuntimeError: DataLoader 2 workers exit unexpectedly, pids: 5558, 5559\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'category_id': 2, 'category': '3', 'score': 0.9923987}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.8799365}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.8282141}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.98525107}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.8384328}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.6641719}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.9989077}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.9478587}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.934828}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.9927108}]\n",
      "[{'category_id': 4, 'category': '5', 'score': 0.9335557}]\n",
      "[{'category_id': 3, 'category': '4', 'score': 0.9801444}]\n",
      "[{'category_id': 4, 'category': '5', 'score': 0.9279965}]\n",
      "[{'category_id': 2, 'category': '3', 'score': 0.97137105}]\n"
     ]
    }
   ],
   "source": [
    "model = pdx.load_model('output/resNet101_vd_ssld/best_model')\r\n",
    "results = []\r\n",
    "root_path = '/home/aistudio/data/dataset/face_data_5/face_image_test'\r\n",
    "for idx in os.listdir(root_path):\r\n",
    "    img_path = os.path.join(root_path,idx)\r\n",
    "    orignal = model.predict(img_path)\r\n",
    "    print(orignal)\r\n",
    "    result = orignal[0]['category']\r\n",
    "    results.append(result)\r\n",
    "\r\n",
    "df = pd.DataFrame(results, columns=['Prediction'])\r\n",
    "df.to_csv('/home/aistudio/result_bird.csv', index=True, index_label='QID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import shutil,os\n",
    " \n",
    "try:\n",
    "    shutil.rmtree(\"/home/aistudio/data/dataset\")\n",
    "except:\n",
    "    print(\"无dataset\")\n",
    "try:\n",
    "    os.remove(\"/home/aistudio/eval.txt\")\n",
    "except:\n",
    "    print(\"无eval.txt\")\n",
    "try:\n",
    "    os.remove(\"/home/aistudio/train.txt\")\n",
    "except:\n",
    "    print(\"无dataset\")\n",
    "try:\n",
    "    shutil.rmtree(\"/home/aistudio/eval\")\n",
    "except:\n",
    "    print(\"无eval\")\n",
    "try:\n",
    "    os.remove(\"/home/aistudio/label.txt\")\n",
    "except:\n",
    "    print(\"无label.txt\")\n",
    "try:\n",
    "    shutil.rmtree(\"/home/aistudio/train\")\n",
    "except:\n",
    "    print(\"无train\")\n",
    "try:\n",
    "    shutil.rmtree(\"/home/aistudio/train\")\n",
    "except:\n",
    "    print(\"无train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
